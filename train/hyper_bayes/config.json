{
    "language"        : "PYTHON",
    "main-file"       : "ngram_nn.py",
    "experiment-name" : "ngram_neural_network",
    "likelihood"      : "GAUSSIAN",
    "variables" : {
        "lr_rate" : {
            "type" : "INT",
            "size" : 1,
            "min"  : 1,
            "max"  : 50
        },
        "n_epochs" : {
            "type" : "INT",
            "size" : 1,
            "min"  : 5,
            "max"  : 20
        },
        "batch_size" : {
            "type" : "INT",
            "size" : 1,
            "min"  : 2,
            "max"  : 40
        },
        "ngram_layers" : {
            "type" : "INT",
            "size" : 1,
            "min"  : 1,
            "max"  : 2
        },
        "use_bias" : {
            "type" : "INT",
            "size" : 1,
            "min"  : 0,
            "max"  : 1
        },
        "n_kernels" : {
            "type" : "INT",
            "size" : 2,
            "min"  : 2,
            "max"  : 16
        },
        "ngrams" : {
            "type" : "INT",
            "size" : 2,
            "min"  : 1,
            "max"  : 3
        },
        "dropout" : {
            "type" : "INT",
            "size" : 1,
            "min"  : 0,
            "max"  : 1
        },
        "dropout_rate" : {
            "type" : "INT",
            "size" : 1,
            "min"  : 1,
            "max"  : 7
        },
        "n_hidden" : {
            "type" : "INT",
            "size" : 1,
            "min"  : 30,
            "max"  : 100
        },
        "mean_pool" : {
            "type" : "INT",
            "size" : 1,
            "min"  : 0,
            "max"  : 1
        }
    }
}